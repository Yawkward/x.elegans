{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n_job for grid searchCV & randomforest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler as zscore # zscore\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso #LRlasso\n",
    "from collections import OrderedDict\n",
    "from joblib import dump, load #to save models in files\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoll change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def gridcv(X, y, model, param_grid, naimpute=False, prepy=True, scorer = 'neg_mean_squared_error', cv_meth = LeaveOneOut(), cv_n_jobs = 1):\n",
    "    \"\"\"\n",
    "    Perform Cross-Validation (defaukt: LOOCV) with hyperparameter tuning using GridSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : pandas DataFrame or numpy array\n",
    "        The feature matrix.\n",
    "        \n",
    "    y : pandas Series or numpy array\n",
    "        The target variable.\n",
    "        \n",
    "    model : scikit-learn estimator\n",
    "        The machine learning model to be used, should be an uninitialized model instance \n",
    "        (e.g., Lasso(), not Lasso(alpha=1.0)).\n",
    "        \n",
    "    param_grid : dict\n",
    "        Dictionary containing the hyperparameters to be tuned and their possible values. \n",
    "        The keys should be prefixed with 'regressor__' to work with the pipeline.\n",
    "        \n",
    "    naimpute : bool, optional (default=False)\n",
    "        Toggle imputation for missing values. \n",
    "        Currently not implemented; will print a message and return 0 if set to True.\n",
    "        \n",
    "    prepy : bool, optional (default=True)\n",
    "        Toggle preprocessing target variable 'y' by setting any negative values to zero.\n",
    "        \n",
    "    scorer : str, callable, or None, optional (default='neg_mean_squared_error')\n",
    "        A string or a scorer callable object / function with signature scorer(estimator, X, y). \n",
    "        For valid scoring strings, see the scikit-learn documentation.\n",
    "        \n",
    "    cv_meth : cross-validation generator, optional (default=LeaveOneOut())\n",
    "        A cross-validation splitting strategy. \n",
    "        Possible inputs for cv are integers to specify the number of folds in a (Stratified)KFold, \n",
    "        CV splitter, cross-validation generator iterators, or an iterable.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    overall_metric : dict\n",
    "        Dictionary containing the overall metrics and other details from the GridSearchCV.\n",
    "        \n",
    "    out_model : GridSearchCV object\n",
    "        Fitted GridSearchCV object.\n",
    "        \n",
    "    best_params : dict\n",
    "        Dictionary containing the best hyperparameters found by GridSearchCV.\n",
    "\n",
    "    Call:\n",
    "    ------\n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    # set up KFold cross-validator\n",
    "    kfold_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    param_grid = {\n",
    "        'regressor__alpha': np.array(np.arange(0.0125, 0.0425, 0.0025)),\n",
    "        'regressor__fit_intercept': [True, False]\n",
    "    }\n",
    "    print(param_grid)\n",
    "\n",
    "    # Call the gridcv function with KFold as the cross-validation method\n",
    "    lasso_fullkfold_scores, lasso_fullkfold_model, best_param = gridcv(\n",
    "        X, \n",
    "        y,\n",
    "        Lasso(max_iter=4000),\n",
    "        param_grid,\n",
    "        scorer='r2', \n",
    "        cv_meth=kfold_cv\n",
    "    )\n",
    "    dump(lasso_fullkfold_model, './models/lasso_fullkfold_model.pkl') # save the model as .pkl\n",
    "    \"\"\"\n",
    "\n",
    "    # overall_metric = {'CV': cv_meth, 'scoring_metric': scorer} originally\n",
    "    overall_metric = {'CV': str(cv_meth), 'scoring_metric': str(scorer)} # transformed to string because json dump scores later\n",
    "\n",
    "    if prepy:\n",
    "        y[y < 0] = 0\n",
    "    \n",
    "    if naimpute:\n",
    "      print(\"not implemented\")\n",
    "      return 0\n",
    "\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', zscore()), \n",
    "        ('regressor', model)        # Regression model\n",
    "    ])\n",
    "\n",
    "    \n",
    "    # declaring an Grid object\n",
    "    # score : https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    out_model = GridSearchCV(pipeline, param_grid=param_grid, cv=cv_meth, scoring=scorer, n_jobs=cv_n_jobs).fit(X,y)\n",
    "    # GridSearchCV need the regressor__ prefix for the pipiline object in the para_grid later when called\n",
    "\n",
    "    best_pipeline = out_model.best_estimator_\n",
    "    y_pred = best_pipeline.predict(X)\n",
    "\n",
    "    overall_metric['correlation_true_pred'] = list(np.corrcoef(list(y), list(y_pred)))\n",
    "    overall_metric['correlation_true_pred'][0] = list(overall_metric['correlation_true_pred'][0])\n",
    "    overall_metric['correlation_true_pred'][1] = list(overall_metric['correlation_true_pred'][1])\n",
    "\n",
    "\n",
    "    # LOOCV folds: split{i}_test_score (number of data points minus one) \n",
    "    overall_metric['fold_scores'] = [out_model.cv_results_[f'split{i}_test_score'][out_model.best_index_] for i in range(out_model.n_splits_)]\n",
    "    best_params = out_model.best_params_\n",
    "\n",
    "\n",
    "    # printing section\n",
    "    print(\"best parameter from gridsearch>>\\n\", out_model.best_params_)\n",
    "    print(overall_metric['CV'])\n",
    "    print(overall_metric['scoring_metric'])\n",
    "    print(\"correlation Matrix>>\\n\", overall_metric['correlation_true_pred'])\n",
    "    print(\"scores for each fold>>\\n\",overall_metric['fold_scores'])\n",
    "\n",
    "    if str(model).startswith(\"Lasso\"):\n",
    "        # access the 'regressor' step from the best pipeline and then its coefficients\n",
    "        coefficients = best_pipeline.named_steps['regressor'].coef_\n",
    "        overall_metric['non_zero_coefficients'] = coefficients[coefficients != 0]\n",
    "        overall_metric['non_zero_coefficients'] = overall_metric['non_zero_coefficients'].tolist()\n",
    "        overall_metric['non_zero_features'] = list(X.columns[np.where(coefficients != 0)[0]])\n",
    "        print(\"non_zero_features>>\\n\",overall_metric['non_zero_features'])\n",
    "\n",
    "    if str(model).startswith(\"RandomForestRegressor\"):\n",
    "        pass\n",
    "        #feature_names = X.columns\n",
    "        #feature_importances = best_pipeline.named_steps['regressor'].feature_importances_\n",
    "        #feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "        #sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        #overall_metric['feature_importances'] = OrderedDict(sorted_feature_importance)\n",
    "        #print(\"feature_importances>>\\n\",overall_metric['feature_importances'])\n",
    "       \n",
    "\n",
    "    return overall_metric, out_model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nX_cross_validation2(X, target, param_grid, scorer_estimate, output_prefix, random_states, output_path='./models/10xKfold/', n_splits=3):\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"The path {output_path} exists.\")\n",
    "    else:\n",
    "        print(f\"The path {output_path} does not exist.\")\n",
    "        raise FileNotFoundError(f\"The path {output_path} does not exist.\")\n",
    "\n",
    "    cv_results = {'random_state': [], 'scores': {}, 'mean_scores': [], 'common_features': {}, 'model': {}}\n",
    "    for ran_state in random_states:\n",
    "        print(ran_state)\n",
    "        kfold_cv = KFold(n_splits=n_splits, shuffle=True, random_state=ran_state)\n",
    "        scores, model, best_param = gridcv(\n",
    "            X, \n",
    "            target,\n",
    "            Lasso(),\n",
    "            param_grid,\n",
    "            prepy=False,\n",
    "            scorer=scorer_estimate, \n",
    "            cv_meth=kfold_cv\n",
    "        )\n",
    "        cv_results['random_state'].append(ran_state)\n",
    "        cv_results['scores'][ran_state] = scores\n",
    "        cv_results['mean_scores'].append(np.mean(scores['fold_scores']))\n",
    "        # cv_results['model'][ran_state] = model\n",
    "\n",
    "    # Determine common features...\n",
    "    cv_results['common_features'] = set(cv_results['scores'][42]['non_zero_features'])\n",
    "    for r in cv_results['random_state'][1:]:\n",
    "        current_features = set(cv_results['scores'][r]['non_zero_features'])\n",
    "        cv_results['common_features'] = cv_results['common_features'].intersection(current_features)\n",
    "    cv_results['common_features'] = list(cv_results['common_features'])\n",
    "\n",
    "    #save to json\n",
    "    with open(f\"{output_path}{output_prefix}_nXcv.json\", 'w') as file:\n",
    "       json.dump(cv_results, file)\n",
    "    file.close()\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REF 1\n",
    "        #if np.mean(scores['fold_scores']) > 0.3:\n",
    "        #    print(f\"\\n >> TRUE, mean fold scores {np.mean(scores['fold_scores'])} is bigger than tresh << \\n\")\n",
    "            # select feature based on cumulative importance\n",
    "        #    cumulative_importance = 0.0\n",
    "        #   selected_features = []\n",
    "        #    for feature, importance in scores['feature_importances'].items():\n",
    "        #        cumulative_importance += importance\n",
    "        #        selected_features.append(feature)\n",
    "        #        if cumulative_importance >= 0.95:\n",
    "        #           break\n",
    "        #    cv_results['selected_features'][ran_state] = selected_features\n",
    "        # cv_results['model'][ran_state] = model\n",
    "\n",
    "    \n",
    "    # Determine common features selected on cumulative importance\n",
    "    #first_key = list(cv_results['selected_features'])[0]\n",
    "    #cv_results['common_features'] = set(cv_results['selected_features'][first_key])\n",
    "\n",
    "    #for r in list(cv_results['selected_features'].keys())[1:]:\n",
    "    #    current_features = set(cv_results['selected_features'][r])\n",
    "    #    cv_results['common_features'] = cv_results['common_features'].intersection(current_features)\n",
    "    #cv_results['common_features'] = list(cv_results['common_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_type(obj):\n",
    "    \"\"\"\n",
    "    Converts an type of numpy into a python inherent type\n",
    "    This function can be used in combination with json.dump:\n",
    "    ----\n",
    "    Usage Example:\n",
    "    \n",
    "    with open(f\"{output_path}{output_prefix}_nXcv.json\", 'w') as file:\n",
    "       json.dump(cv_results, file, default=convert_type)\n",
    "    \"\"\"\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nX_cross_validation(X, target, param_grid, scorer_estimate, output_prefix, random_states, output_path='./models/10xKfold/', n_splits=3, cv_n_jobs=1, regr_n_job=1):\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"The path {output_path} exists.\")\n",
    "    else:\n",
    "        print(f\"The path {output_path} does not exist.\")\n",
    "        raise FileNotFoundError(f\"The path {output_path} does not exist.\")\n",
    "    best_fold_mean = float('-inf')\n",
    "    best_model = []\n",
    "\n",
    "    #cv_results = {'random_state': [], 'scores': {}, 'mean_scores': [], 'selected_features': {}, 'common_features': {}, 'model': {}}\n",
    "    cv_results = {'random_state': [], 'scores': {}, 'mean_scores': [], 'selected_features': {}, 'best_param': []}\n",
    "\n",
    "    for ran_state in random_states:\n",
    "        print(ran_state)\n",
    "        kfold_cv = KFold(n_splits=n_splits, shuffle=True, random_state=ran_state)\n",
    "        scores, model, best_param = gridcv(\n",
    "            X, \n",
    "            target,\n",
    "            RandomForestRegressor(n_jobs=regr_n_job),\n",
    "            param_grid,\n",
    "            prepy=False,\n",
    "            scorer=scorer_estimate, \n",
    "            cv_meth=kfold_cv,\n",
    "            cv_n_jobs=cv_n_jobs\n",
    "        )\n",
    "        cv_results['random_state'].append(ran_state)\n",
    "        cv_results['scores'][ran_state] = scores\n",
    "        cv_results['mean_scores'].append(np.mean(scores['fold_scores']))\n",
    "        if best_fold_mean < np.mean(scores['fold_scores']):\n",
    "            best_fold_mean = np.mean(scores['fold_scores'])\n",
    "            cv_results['best_param'] = best_param, ran_state, np.mean(scores['fold_scores'])\n",
    "\n",
    "    # REF 1\n",
    "\n",
    "    print(f\"best estimator>>\\n found in split: {cv_results['best_param'][1]}\\n param_grid: {cv_results['best_param'][0]}\\n mean fold score {cv_results['best_param'][2]}\")    \n",
    "    regr = RandomForestRegressor(max_features=cv_results['best_param'][0]['regressor__max_features'], n_estimators=cv_results['best_param'][0]['regressor__n_estimators'], bootstrap=cv_results['best_param'][0]['regressor__bootstrap'], n_jobs=regr_n_job)\n",
    "    best_model = regr.fit(X, target)\n",
    "    feature_names = X.columns\n",
    "    feature_importances = best_model.feature_importances_\n",
    "    feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "    sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_feature_importance = OrderedDict(sorted_feature_importance)\n",
    "    # select feature based on cumulative importance\n",
    "    cumulative_importance = 0.0\n",
    "    selected_features = []\n",
    "    for feature, importance in sorted_feature_importance.items():\n",
    "        print(f\"feaute, {feature},  import, {importance}\")\n",
    "        cumulative_importance += importance\n",
    "        selected_features.append(feature)\n",
    "        if cumulative_importance >= 0.95:\n",
    "            break\n",
    "    cv_results['selected_features'] = selected_features\n",
    "\n",
    "    #save to json\n",
    "    with open(f\"{output_path}{output_prefix}_nXcv.json\", 'w') as file:\n",
    "       json.dump(cv_results, file, default=convert_type)\n",
    "    file.close()\n",
    "    \n",
    "    return cv_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_valid_variable_name(name):\n",
    "    # Replace special characters with underscores\n",
    "    name = re.sub(r'\\W|^(?=\\d)', '_', name)\n",
    "    # Reduce multiple consecutive underscores to one\n",
    "    name = re.sub(r'_{2,}', '_', name)\n",
    "    # Truncate length if necessary\n",
    "    max_length = 30\n",
    "    if len(name) > max_length:\n",
    "        name = name[:max_length]\n",
    "    # Ensure it doesn't start with a number\n",
    "    if name[0].isdigit():\n",
    "        name = \"_\" + name\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mut = pd.read_csv(\"/home/t44p/PW_rawdata/tr_gc_mutual/tr_mut.csv\", sep=\",\")\n",
    "gcms_mut = pd.read_csv(\"/home/t44p/PW_rawdata/tr_gc_mutual/gcms_mut.csv\", sep=\",\")\n",
    "lcms_mut = pd.read_csv(\"/home/t44p/PW_rawdata/tr_gc_mutual/lcms_mut.csv\", sep=\",\")\n",
    "\n",
    "X = pd.read_csv(\"/home/t44p/PW_rawdata/tr_gc_mutual/tr_mut_transposed.csv\", sep=\",\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06115402 0.19094228 0.26527444 0.29463637 0.32083137 0.33420758\n",
      " 0.04894513 0.22726775 0.31350062 0.3055881  0.27004845 0.35836926\n",
      " 0.40416474 0.05106125 0.2216727  0.29773878 0.31415813 0.32469304\n",
      " 0.40883514 0.36435307 0.21304547 0.45176721 0.42762626 0.41732094\n",
      " 0.38741296 0.3525298  0.30096443 0.37433194 0.43484489 0.34584996\n",
      " 0.41922279 0.321271   0.42421353 0.44178561 0.42598215 0.35318408\n",
      " 0.31890495 0.30005904 0.36642328 0.44253155]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_features=4, n_informative=2,\n",
    "                       random_state=0, shuffle=False)\"\"\"\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0, n_jobs=3)\n",
    "regr.fit(X.iloc[:,:], gcms_mut.iloc[59,1:])\n",
    "print(regr.predict(X.iloc[:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter from gridsearch>>\n",
      " {'regressor__alpha': 0.0175, 'regressor__fit_intercept': True}\n",
      "KFold(n_splits=3, random_state=42, shuffle=True)\n",
      "r2\n",
      "correlation Matrix>>\n",
      " [[1.0, 0.7481332260894714], [0.7481332260894714, 0.9999999999999998]]\n",
      "scores for each fold>>\n",
      " [0.7720139897938894, 0.3313252228931619, 0.25279959004526065]\n",
      "non_zero_features>>\n",
      " ['Xele.ptg000045l.1', 'Xele.ptg000045l.6', 'Xele.ptg000045l.8', 'Xele.ptg000045l.10']\n"
     ]
    }
   ],
   "source": [
    "kfold_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__alpha': np.array(np.arange(0.0125, 0.0425, 0.0025)),\n",
    "    'regressor__fit_intercept': [True, False]\n",
    "}   \n",
    "lasso_fullkfold_scores, lasso_fullkfold_model, lasso_best_param = gridcv(\n",
    "    X.iloc[:,0:10], \n",
    "    gcms_mut.iloc[59,1:],\n",
    "    Lasso(max_iter=4000),\n",
    "    param_grid,\n",
    "    scorer='r2', \n",
    "    cv_meth=kfold_cv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "feature_names = X.columns\n",
    "feature_importances = regr.feature_importances_\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "# sort this dictionary based on importances\n",
    "sorted_feature_importance = OrderedDict(sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "print(type(sorted_feature_importance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 147, 1176, 9410])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.log10(np.array(np.arange(200, 1401, 600)))#\n",
    "np.round(np.exp2(np.array(np.arange(7.2, 15.3, 3)))).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the run below took 16 min on the full X\n",
    "\n",
    ">explore a better grid on the cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'regressor__n_estimators': [ 500  700  900 1100 1300 1500]\n",
      "'regressor__max_features':[   9   37  147  588 2353 9410]\n",
      "'regressor__n_estimators': [10 11 12 13 14]\n",
      "'regressor__max_features':[7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(f\"'regressor__n_estimators': {np.array(np.arange(500, 1501, 200))}\")\n",
    "print(f\"'regressor__max_features':{np.round(np.exp2(np.array(np.arange(3.2, 13.3, 2)))).astype(int)}\")\n",
    "print(f\"'regressor__n_estimators': {np.array(np.arange(10, 15, 1))}\")\n",
    "print(f\"'regressor__max_features':{np.array(np.arange(7, 10, 1))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter from gridsearch>>\n",
      " {'regressor__bootstrap': True, 'regressor__max_features': 1176, 'regressor__n_estimators': 500}\n",
      "KFold(n_splits=3, random_state=42, shuffle=True)\n",
      "r2\n",
      "correlation Matrix>>\n",
      " [[1.0, 0.9752316306083173], [0.9752316306083174, 1.0]]\n",
      "scores for each fold>>\n",
      " [0.5069292268821795, 0.6047388361149414, 0.2653775032594198]\n",
      "feature_importances>>\n",
      " OrderedDict([('Xele.ptg000045l.50', 0.41926256928952893), ('Xele.ptg000045l.1', 0.05245621017973865), ('Xele.ptg000045l.18', 0.03649779466045334), ('Xele.ptg000045l.15', 0.03332675667963292), ('Xele.ptg000045l.93', 0.0328994032125989), ('Xele.ptg000045l.100', 0.030150458190898618), ('Xele.ptg000045l.98', 0.020536180125984703), ('Xele.ptg000045l.108', 0.015845226685376773), ('Xele.ptg000045l.101', 0.015688698118336536), ('Xele.ptg000045l.59', 0.013549898156599452), ('Xele.ptg000045l.74', 0.011384589630555634), ('Xele.ptg000045l.19', 0.01047043602816892), ('Xele.ptg000045l.103', 0.01044245988667525), ('Xele.ptg000045l.87', 0.009897771433549887), ('Xele.ptg000045l.83', 0.009748851858112561), ('Xele.ptg000045l.107', 0.009731605806514436), ('Xele.ptg000045l.20', 0.009409734409828707), ('Xele.ptg000045l.51', 0.009242141206986429), ('Xele.ptg000045l.77', 0.00851207040104333), ('Xele.ptg000045l.37', 0.008157593820067876), ('Xele.ptg000045l.56', 0.008041981768319505), ('Xele.ptg000045l.85', 0.00787904482111572), ('Xele.ptg000045l.86', 0.007830620891321841), ('Xele.ptg000045l.11', 0.007670575306764498), ('Xele.ptg000045l.54', 0.0075516329478139705), ('Xele.ptg000045l.79', 0.007223986390425954), ('Xele.ptg000045l.68', 0.0068069022962538375), ('Xele.ptg000045l.75', 0.005974222951376355), ('Xele.ptg000045l.43', 0.0057452999769844445), ('Xele.ptg000045l.28', 0.00522533440538416), ('Xele.ptg000045l.105', 0.005206643156070516), ('Xele.ptg000045l.99', 0.005092570119794008), ('Xele.ptg000045l.44', 0.0050403279537463855), ('Xele.ptg000045l.89', 0.004958587644791394), ('Xele.ptg000045l.2', 0.004940524963259058), ('Xele.ptg000045l.41', 0.004559241703697088), ('Xele.ptg000045l.21', 0.004486773698759091), ('Xele.ptg000045l.7', 0.004421411267505578), ('Xele.ptg000045l.112', 0.00415419262195862), ('Xele.ptg000045l.36', 0.004116605077553545), ('Xele.ptg000045l.16', 0.00410158066646659), ('Xele.ptg000045l.40', 0.003975161566483413), ('Xele.ptg000045l.55', 0.003802719457912101), ('Xele.ptg000045l.69', 0.003713223506861758), ('Xele.ptg000045l.34', 0.0035654640475384944), ('Xele.ptg000045l.48', 0.0032868308401074815), ('Xele.ptg000045l.6', 0.0031061900382009467), ('Xele.ptg000045l.96', 0.0030450572378804596), ('Xele.ptg000045l.31', 0.00292838767002817), ('Xele.ptg000045l.73', 0.0029087760036548517), ('Xele.ptg000045l.42', 0.0028268084199834184), ('Xele.ptg000045l.109', 0.00277304818194267), ('Xele.ptg000045l.58', 0.0027044953732347212), ('Xele.ptg000045l.92', 0.0024626306210733953), ('Xele.ptg000045l.9', 0.0024463657922360812), ('Xele.ptg000045l.23', 0.002440616401883119), ('Xele.ptg000045l.106', 0.0023805939108776123), ('Xele.ptg000045l.64', 0.002367754502324341), ('Xele.ptg000045l.60', 0.0022664030339767265), ('Xele.ptg000045l.66', 0.002233474179961518), ('Xele.ptg000045l.84', 0.002214899189529785), ('Xele.ptg000212l.1', 0.0021505296730416424), ('Xele.ptg000045l.104', 0.0021290650426399192), ('Xele.ptg000045l.8', 0.002102450281189068), ('Xele.ptg000045l.33', 0.002078700460238758), ('Xele.ptg000045l.22', 0.00205648882866815), ('Xele.ptg000045l.70', 0.002041123623651638), ('Xele.ptg000045l.10', 0.0020115063108933936), ('Xele.ptg000045l.82', 0.001970404199825565), ('Xele.ptg000045l.29', 0.0019525405086060026), ('Xele.ptg000045l.26', 0.0019448533646018926), ('Xele.ptg000045l.72', 0.0019267143134941219), ('Xele.ptg000045l.25', 0.0017652548112349266), ('Xele.ptg000045l.62', 0.0017020112971643056), ('Xele.ptg000045l.102', 0.0016177677774817842), ('Xele.ptg000045l.65', 0.001547497691841384), ('Xele.ptg000045l.110', 0.0014505321887456658), ('Xele.ptg000045l.61', 0.0014223493084137575), ('Xele.ptg000045l.57', 0.0013737300448878245), ('Xele.ptg000045l.14', 0.0013524576183583526), ('Xele.ptg000045l.39', 0.0013255273109634093), ('Xele.ptg000045l.52', 0.0012985020350172038), ('Xele.ptg000045l.24', 0.0012232465213161236), ('Xele.ptg000045l.27', 0.0011878788281167935), ('Xele.ptg000045l.49', 0.0011870222806800465), ('Xele.ptg000045l.53', 0.0011671803970418687), ('Xele.ptg000045l.111', 0.0011156802424881166), ('Xele.ptg000045l.97', 0.0010446417881871323), ('Xele.ptg000045l.95', 0.0010250477057957908), ('Xele.ptg000045l.38', 0.0010010137293381162), ('Xele.ptg000045l.76', 0.0009976767942567796), ('Xele.ptg000045l.45', 0.0009632338265679148), ('Xele.ptg000045l.46', 0.0009080848651844996), ('Xele.ptg000045l.78', 0.0008885527546289368), ('Xele.ptg000045l.47', 0.0008856070616128945), ('Xele.ptg000045l.94', 0.0008709707670192472), ('Xele.ptg000045l.80', 0.0008416385207425229), ('Xele.ptg000045l.32', 0.0008093414819891444), ('Xele.ptg000045l.71', 0.0005374147835741026), ('Xele.ptg000045l.88', 0.00043835057479600767)])\n"
     ]
    }
   ],
   "source": [
    "kfold_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': np.array(np.arange(500, 1501, 1000)),\n",
    "    'regressor__max_features': np.round(np.exp2(np.array(np.arange(7.2, 15.3, 3)))).astype(int),\n",
    "    'regressor__bootstrap': [False, True]\n",
    "}   \n",
    "rfr_fullkfold_scores, rfr_fullkfold_model, rfr_best_param = gridcv(\n",
    "    X.iloc[:,:100], \n",
    "    gcms_mut.iloc[59,1:],\n",
    "    RandomForestRegressor(n_jobs=2),\n",
    "    param_grid,\n",
    "    scorer='r2', \n",
    "    cv_meth=kfold_cv,\n",
    "    cv_n_jobs=2\n",
    ")\n",
    "#for key, value in rfr_fullkfold_scores.items():\n",
    "#    print(f\"{key} >>>>\\n {value}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFR START >>> sucrose_437_361_rt13_77\n",
      "\n",
      "\n",
      "The path ./py/10xKfold/test_rfr/ exists.\n",
      "42\n",
      "best parameter from gridsearch>>\n",
      " {'regressor__bootstrap': True, 'regressor__max_features': 9, 'regressor__n_estimators': 13}\n",
      "KFold(n_splits=3, random_state=42, shuffle=True)\n",
      "r2\n",
      "correlation Matrix>>\n",
      " [[1.0, 0.9704156298966722], [0.9704156298966721, 0.9999999999999999]]\n",
      "scores for each fold>>\n",
      " [0.5411879858317737, 0.42902222689265, 0.2822698944408427]\n",
      "43\n",
      "best parameter from gridsearch>>\n",
      " {'regressor__bootstrap': False, 'regressor__max_features': 8, 'regressor__n_estimators': 12}\n",
      "KFold(n_splits=3, random_state=43, shuffle=True)\n",
      "r2\n",
      "correlation Matrix>>\n",
      " [[1.0, 0.9999999999999998], [0.9999999999999998, 1.0]]\n",
      "scores for each fold>>\n",
      " [0.3675948428691159, 0.5552435547838133, 0.4849802299742626]\n",
      "44\n",
      "best parameter from gridsearch>>\n",
      " {'regressor__bootstrap': True, 'regressor__max_features': 9, 'regressor__n_estimators': 14}\n",
      "KFold(n_splits=3, random_state=44, shuffle=True)\n",
      "r2\n",
      "correlation Matrix>>\n",
      " [[1.0, 0.9821567100486803], [0.9821567100486802, 1.0]]\n",
      "scores for each fold>>\n",
      " [-0.8860830853227328, 0.05531706760656907, 0.10209878573802644]\n",
      "best estimator>>\n",
      " found in split: 43\n",
      " param_grid: {'regressor__bootstrap': False, 'regressor__max_features': 8, 'regressor__n_estimators': 12}\n",
      " mean fold score 0.4692728758757306\n",
      "feaute, Xele.ptg000045l.89,  import, 0.0967748458245493\n",
      "feaute, Xele.ptg000045l.69,  import, 0.08129735496520252\n",
      "feaute, Xele.ptg000045l.1,  import, 0.08121914539600132\n",
      "feaute, Xele.ptg000045l.7,  import, 0.07378485912744688\n",
      "feaute, Xele.ptg000045l.21,  import, 0.06109753550438623\n",
      "feaute, Xele.ptg000045l.50,  import, 0.05355821443815149\n",
      "feaute, Xele.ptg000045l.20,  import, 0.04948522094101041\n",
      "feaute, Xele.ptg000045l.2,  import, 0.04048853934116301\n",
      "feaute, Xele.ptg000045l.108,  import, 0.03032346832492486\n",
      "feaute, Xele.ptg000045l.77,  import, 0.02855472607494065\n",
      "feaute, Xele.ptg000045l.61,  import, 0.027332335787869765\n",
      "feaute, Xele.ptg000045l.93,  import, 0.026404620201863013\n",
      "feaute, Xele.ptg000045l.25,  import, 0.020004337193696296\n",
      "feaute, Xele.ptg000045l.15,  import, 0.01948684838054869\n",
      "feaute, Xele.ptg000045l.43,  import, 0.019374484090040393\n",
      "feaute, Xele.ptg000045l.56,  import, 0.018983477562824466\n",
      "feaute, Xele.ptg000045l.73,  import, 0.018158747716531386\n",
      "feaute, Xele.ptg000045l.98,  import, 0.01777192329917645\n",
      "feaute, Xele.ptg000045l.59,  import, 0.015421584350707838\n",
      "feaute, Xele.ptg000045l.86,  import, 0.015042626155742075\n",
      "feaute, Xele.ptg000045l.9,  import, 0.01470341044951815\n",
      "feaute, Xele.ptg000045l.18,  import, 0.012096052922148328\n",
      "feaute, Xele.ptg000045l.37,  import, 0.011570176422234164\n",
      "feaute, Xele.ptg000045l.44,  import, 0.011483832331909397\n",
      "feaute, Xele.ptg000045l.68,  import, 0.010241067316279268\n",
      "feaute, Xele.ptg000045l.74,  import, 0.009139601332703912\n",
      "feaute, Xele.ptg000045l.85,  import, 0.0076799793074265625\n",
      "feaute, Xele.ptg000045l.48,  import, 0.006732753461266898\n",
      "feaute, Xele.ptg000045l.36,  import, 0.006696730421258119\n",
      "feaute, Xele.ptg000045l.34,  import, 0.006658779790370599\n",
      "feaute, Xele.ptg000045l.107,  import, 0.006640656668334692\n",
      "feaute, Xele.ptg000045l.54,  import, 0.00574399654882465\n",
      "feaute, Xele.ptg000045l.51,  import, 0.00543782994866441\n",
      "feaute, Xele.ptg000045l.88,  import, 0.004987751110607398\n",
      "feaute, Xele.ptg000045l.105,  import, 0.004958802464090144\n",
      "feaute, Xele.ptg000045l.101,  import, 0.004460618432910991\n",
      "feaute, Xele.ptg000045l.100,  import, 0.004010693417427101\n",
      "feaute, Xele.ptg000045l.71,  import, 0.003995932475623679\n",
      "feaute, Xele.ptg000045l.11,  import, 0.0037052305914648982\n",
      "feaute, Xele.ptg000045l.22,  import, 0.003530856744900865\n",
      "feaute, Xele.ptg000045l.41,  import, 0.003474925970930781\n",
      "feaute, Xele.ptg000045l.16,  import, 0.0033497874690472406\n",
      "feaute, Xele.ptg000045l.87,  import, 0.003060551104994805\n",
      "feaute, Xele.ptg000045l.92,  import, 0.003023225381566889\n"
     ]
    }
   ],
   "source": [
    "print(f\"RFR START >>> {to_valid_variable_name(str(gcms_mut.iloc[59,0]))}\\n\\n\")\n",
    "tenX = [42, 43, 44]#, 45, 46, 47, 48, 49, 50, 51, 52]\n",
    "out = './py/10xKfold/test_rfr/'\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': np.array(np.arange(10, 15, 1)),\n",
    "    'regressor__max_features': np.array(np.arange(7, 10, 1)),\n",
    "    'regressor__bootstrap': [False, True]\n",
    "}   \n",
    "sucrose_10xKfold = nX_cross_validation(X.iloc[:,:100], gcms_mut.iloc[59,1:], param_grid, 'r2', to_valid_variable_name(str(gcms_mut.iloc[59,0])), tenX, output_path=out, cv_n_jobs=2, regr_n_job=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Xele.ptg000045l.101',\n",
       " 'Xele.ptg000045l.50',\n",
       " 'Xele.ptg000045l.28',\n",
       " 'Xele.ptg000045l.1',\n",
       " 'Xele.ptg000045l.107',\n",
       " 'Xele.ptg000045l.89',\n",
       " 'Xele.ptg000045l.21',\n",
       " 'Xele.ptg000045l.25',\n",
       " 'Xele.ptg000045l.93',\n",
       " 'Xele.ptg000045l.98',\n",
       " 'Xele.ptg000045l.6',\n",
       " 'Xele.ptg000045l.87',\n",
       " 'Xele.ptg000045l.16',\n",
       " 'Xele.ptg000045l.7',\n",
       " 'Xele.ptg000045l.24',\n",
       " 'Xele.ptg000045l.56',\n",
       " 'Xele.ptg000045l.74',\n",
       " 'Xele.ptg000045l.78',\n",
       " 'Xele.ptg000045l.94',\n",
       " 'Xele.ptg000045l.84',\n",
       " 'Xele.ptg000045l.41',\n",
       " 'Xele.ptg000045l.69',\n",
       " 'Xele.ptg000045l.68',\n",
       " 'Xele.ptg000045l.108',\n",
       " 'Xele.ptg000045l.20',\n",
       " 'Xele.ptg000045l.19',\n",
       " 'Xele.ptg000045l.102',\n",
       " 'Xele.ptg000045l.54',\n",
       " 'Xele.ptg000045l.15',\n",
       " 'Xele.ptg000045l.38',\n",
       " 'Xele.ptg000045l.92',\n",
       " 'Xele.ptg000045l.100',\n",
       " 'Xele.ptg000045l.73',\n",
       " 'Xele.ptg000045l.33',\n",
       " 'Xele.ptg000045l.58',\n",
       " 'Xele.ptg000045l.36',\n",
       " 'Xele.ptg000045l.26',\n",
       " 'Xele.ptg000045l.42',\n",
       " 'Xele.ptg000045l.55',\n",
       " 'Xele.ptg000045l.112',\n",
       " 'Xele.ptg000045l.76',\n",
       " 'Xele.ptg000045l.65',\n",
       " 'Xele.ptg000045l.44',\n",
       " 'Xele.ptg000045l.8',\n",
       " 'Xele.ptg000045l.103',\n",
       " 'Xele.ptg000045l.109',\n",
       " 'Xele.ptg000045l.72',\n",
       " 'Xele.ptg000045l.80',\n",
       " 'Xele.ptg000045l.43']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for ele in sucrose_10xKfold['selected_features']:\n",
    "#    print(f\"{sucrose_10xKfold['selected_features'][ele]}\")\n",
    "sucrose_10xKfold['mean_scores']\n",
    "\n",
    "sucrose_10xKfold.keys()\n",
    "\n",
    "\n",
    "sucrose_10xKfold['selected_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features >>\n",
      " 1000\n",
      "median >> \n",
      " 0.0\n",
      " med_sel_feat>>\n",
      "1000\n",
      "selected features >> \n",
      "62\n"
     ]
    }
   ],
   "source": [
    "med_sel_feets = []\n",
    "for key, val in rfr_fullkfold_scores['feature_importances'].items():\n",
    "    if val >= np.median(list(rfr_fullkfold_scores['feature_importances'].values())):\n",
    "        med_sel_feets.append(key)\n",
    "\n",
    "\n",
    "cumulative_importance = 0.0\n",
    "selected_features = []\n",
    "\n",
    "for feature, importance in rfr_fullkfold_scores['feature_importances'].items():\n",
    "    cumulative_importance += importance\n",
    "    selected_features.append(feature)\n",
    "    if cumulative_importance >= 0.95:\n",
    "        break\n",
    "\n",
    "print(f\"features >>\\n {len(rfr_fullkfold_scores['feature_importances'].keys())}\\nmedian >> \\n {np.median(list(rfr_fullkfold_scores['feature_importances'].values()))}\\n med_sel_feat>>\\n{len(med_sel_feets)}\\nselected features >> \\n{len(selected_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xele.ptg000045l.169'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rfr_fullkfold_scores['feature_importances'])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ida_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
