{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c8be24-d0a2-40ba-aa7e-360b4b216785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.preprocessing import StandardScaler as zscore # zscore\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso #LRlasso\n",
    "from joblib import dump, load #to save models in files\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd92f66-9e5b-4e53-ac60-a08bf9b19fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def gridcv(X, y, model, param_grid, naimpute=False, prepy=True, scorer = 'neg_mean_squared_error', cv_meth = LeaveOneOut()):\n",
    "    \"\"\"\n",
    "    Perform Cross-Validation (defaukt: LOOCV) with hyperparameter tuning using GridSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : pandas DataFrame or numpy array\n",
    "        The feature matrix.\n",
    "        \n",
    "    y : pandas Series or numpy array\n",
    "        The target variable.\n",
    "        \n",
    "    model : scikit-learn estimator\n",
    "        The machine learning model to be used, should be an uninitialized model instance \n",
    "        (e.g., Lasso(), not Lasso(alpha=1.0)).\n",
    "        \n",
    "    param_grid : dict\n",
    "        Dictionary containing the hyperparameters to be tuned and their possible values. \n",
    "        The keys should be prefixed with 'regressor__' to work with the pipeline.\n",
    "        \n",
    "    naimpute : bool, optional (default=False)\n",
    "        Toggle imputation for missing values. \n",
    "        Currently not implemented; will print a message and return 0 if set to True.\n",
    "        \n",
    "    prepy : bool, optional (default=True)\n",
    "        Toggle preprocessing target variable 'y' by setting any negative values to zero.\n",
    "        \n",
    "    scorer : str, callable, or None, optional (default='neg_mean_squared_error')\n",
    "        A string or a scorer callable object / function with signature scorer(estimator, X, y). \n",
    "        For valid scoring strings, see the scikit-learn documentation.\n",
    "        \n",
    "    cv_meth : cross-validation generator, optional (default=LeaveOneOut())\n",
    "        A cross-validation splitting strategy. \n",
    "        Possible inputs for cv are integers to specify the number of folds in a (Stratified)KFold, \n",
    "        CV splitter, cross-validation generator iterators, or an iterable.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    overall_metric : dict\n",
    "        Dictionary containing the overall metrics and other details from the GridSearchCV.\n",
    "        \n",
    "    out_model : GridSearchCV object\n",
    "        Fitted GridSearchCV object.\n",
    "        \n",
    "    best_params : dict\n",
    "        Dictionary containing the best hyperparameters found by GridSearchCV.\n",
    "\n",
    "    Call:\n",
    "    ------\n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    # set up KFold cross-validator\n",
    "    kfold_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    param_grid = {\n",
    "        'regressor__alpha': np.array(np.arange(0.0125, 0.0425, 0.0025)),\n",
    "        'regressor__fit_intercept': [True, False]\n",
    "    }\n",
    "    print(param_grid)\n",
    "\n",
    "    # Call the gridcv function with KFold as the cross-validation method\n",
    "    lasso_fullkfold_scores, lasso_fullkfold_model, best_param = gridcv(\n",
    "        X, \n",
    "        y,\n",
    "        Lasso(max_iter=4000),\n",
    "        param_grid,\n",
    "        scorer='r2', \n",
    "        cv_meth=kfold_cv\n",
    "    )\n",
    "    dump(lasso_fullkfold_model, './models/lasso_fullkfold_model.pkl') # save the model as .pkl\n",
    "    \"\"\"\n",
    "\n",
    "    # overall_metric = {'CV': cv_meth, 'scoring_metric': scorer} originally\n",
    "    overall_metric = {'CV': str(cv_meth), 'scoring_metric': str(scorer)} # transformed to string because json dump scores later\n",
    "\n",
    "    if prepy:\n",
    "        y[y < 0] = 0\n",
    "    \n",
    "    if naimpute:\n",
    "      print(\"not implemented\")\n",
    "      return 0\n",
    "\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', zscore()), \n",
    "        ('regressor', model)        # Regression model\n",
    "    ])\n",
    "\n",
    "    \n",
    "    # declaring an Grid object\n",
    "    # score : https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    out_model = GridSearchCV(pipeline, param_grid=param_grid, cv=cv_meth, scoring=scorer).fit(X,y)\n",
    "    # GridSearchCV need the regressor__ prefix for the pipiline object in the para_grid later when called\n",
    "\n",
    "    best_pipeline = out_model.best_estimator_\n",
    "    y_pred = best_pipeline.predict(X)\n",
    "\n",
    "    overall_metric['correlation_true_pred'] = list(np.corrcoef(list(y), list(y_pred)))\n",
    "    overall_metric['correlation_true_pred'][0] = list(overall_metric['correlation_true_pred'][0])\n",
    "    overall_metric['correlation_true_pred'][1] = list(overall_metric['correlation_true_pred'][1])\n",
    "\n",
    "\n",
    "    # LOOCV folds: split{i}_test_score (number of data points minus one) \n",
    "    overall_metric['fold_scores'] = [out_model.cv_results_[f'split{i}_test_score'][out_model.best_index_] for i in range(out_model.n_splits_)]\n",
    "    best_params = out_model.best_params_\n",
    "\n",
    "\n",
    "    # access the 'regressor' step from the best pipeline and then its coefficients\n",
    "    coefficients = best_pipeline.named_steps['regressor'].coef_\n",
    "    overall_metric['non_zero_coefficients'] = coefficients[coefficients != 0]\n",
    "    overall_metric['non_zero_coefficients'] = overall_metric['non_zero_coefficients'].tolist()\n",
    "    overall_metric['non_zero_features'] = list(X.columns[np.where(coefficients != 0)[0]])\n",
    "\n",
    "    # printing section\n",
    "    print(\"best parameter from gridsearch>>\\n\", out_model.best_params_)\n",
    "    print(overall_metric['CV'])\n",
    "    print(overall_metric['scoring_metric'])\n",
    "    print(\"correlation Matrix>>\\n\", overall_metric['correlation_true_pred'])\n",
    "    print(\"non_zero_features>>\\n\",overall_metric['non_zero_features'])\n",
    "    print(\"scores for each fold>>\\n\",overall_metric['fold_scores'])\n",
    "\n",
    "    return overall_metric, out_model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe45f80-ad45-4cbe-ad90-3252058ca2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mut = pd.read_csv(\"/home/t44p/PW_rawdata/tr_gc_mutual/tr_mut.csv\", sep=\",\")\n",
    "gcms_mut = pd.read_csv(\"/home/t44p/PW_rawdata/tr_gc_mutual/gcms_mut.csv\", sep=\",\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ida_tf)",
   "language": "python",
   "name": "ida_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
