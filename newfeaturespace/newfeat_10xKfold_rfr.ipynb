{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Regressor with reduced feature space\n",
    "- WGCNA was used to cluster the transcription data\n",
    "- account for multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler as zscore # zscore\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso #LRlasso\n",
    "from collections import OrderedDict\n",
    "from joblib import dump, load #to save models in files\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def gridcv(X, y, model, param_grid, naimpute=False, prepy=True, scorer = 'neg_mean_squared_error', cv_meth = LeaveOneOut(), cv_n_jobs = 1):\n",
    "    \"\"\"\n",
    "    Perform Cross-Validation (defaukt: LOOCV) with hyperparameter tuning using GridSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : pandas DataFrame or numpy array\n",
    "        The feature matrix.\n",
    "        \n",
    "    y : pandas Series or numpy array\n",
    "        The target variable.\n",
    "        \n",
    "    model : scikit-learn estimator\n",
    "        The machine learning model to be used, should be an uninitialized model instance \n",
    "        (e.g., Lasso(), not Lasso(alpha=1.0)).\n",
    "        \n",
    "    param_grid : dict\n",
    "        Dictionary containing the hyperparameters to be tuned and their possible values. \n",
    "        The keys should be prefixed with 'regressor__' to work with the pipeline.\n",
    "        \n",
    "    naimpute : bool, optional (default=False)\n",
    "        Toggle imputation for missing values. \n",
    "        Currently not implemented; will print a message and return 0 if set to True.\n",
    "        \n",
    "    prepy : bool, optional (default=True)\n",
    "        Toggle preprocessing target variable 'y' by setting any negative values to zero.\n",
    "        \n",
    "    scorer : str, callable, or None, optional (default='neg_mean_squared_error')\n",
    "        A string or a scorer callable object / function with signature scorer(estimator, X, y). \n",
    "        For valid scoring strings, see the scikit-learn documentation.\n",
    "        \n",
    "    cv_meth : cross-validation generator, optional (default=LeaveOneOut())\n",
    "        A cross-validation splitting strategy. \n",
    "        Possible inputs for cv are integers to specify the number of folds in a (Stratified)KFold, \n",
    "        CV splitter, cross-validation generator iterators, or an iterable.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    overall_metric : dict\n",
    "        Dictionary containing the overall metrics and other details from the GridSearchCV.\n",
    "        \n",
    "    out_model : GridSearchCV object\n",
    "        Fitted GridSearchCV object.\n",
    "        \n",
    "    best_params : dict\n",
    "        Dictionary containing the best hyperparameters found by GridSearchCV.\n",
    "\n",
    "    Call:\n",
    "    ------\n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    # set up KFold cross-validator\n",
    "    kfold_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    param_grid = {\n",
    "        'regressor__alpha': np.array(np.arange(0.0125, 0.0425, 0.0025)),\n",
    "        'regressor__fit_intercept': [True, False]\n",
    "    }\n",
    "    print(param_grid)\n",
    "\n",
    "    # Call the gridcv function with KFold as the cross-validation method\n",
    "    lasso_fullkfold_scores, lasso_fullkfold_model, best_param = gridcv(\n",
    "        X, \n",
    "        y,\n",
    "        Lasso(max_iter=4000),\n",
    "        param_grid,\n",
    "        scorer='r2', \n",
    "        cv_meth=kfold_cv\n",
    "    )\n",
    "    dump(lasso_fullkfold_model, './models/lasso_fullkfold_model.pkl') # save the model as .pkl\n",
    "    \"\"\"\n",
    "\n",
    "    # overall_metric = {'CV': cv_meth, 'scoring_metric': scorer} originally\n",
    "    overall_metric = {'CV': str(cv_meth), 'scoring_metric': str(scorer)} # transformed to string because json dump scores later\n",
    "\n",
    "    if prepy:\n",
    "        y[y < 0] = 0\n",
    "    \n",
    "    if naimpute:\n",
    "      print(\"not implemented\")\n",
    "      return 0\n",
    "\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', zscore()), \n",
    "        ('regressor', model)        # Regression model\n",
    "    ])\n",
    "\n",
    "    \n",
    "    # declaring an Grid object\n",
    "    # score : https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    out_model = GridSearchCV(pipeline, param_grid=param_grid, cv=cv_meth, scoring=scorer, n_jobs=cv_n_jobs).fit(X,y)\n",
    "    # GridSearchCV need the regressor__ prefix for the pipiline object in the para_grid later when called\n",
    "\n",
    "    best_pipeline = out_model.best_estimator_\n",
    "    y_pred = best_pipeline.predict(X)\n",
    "\n",
    "    overall_metric['correlation_true_pred'] = list(np.corrcoef(list(y), list(y_pred)))\n",
    "    overall_metric['correlation_true_pred'][0] = list(overall_metric['correlation_true_pred'][0])\n",
    "    overall_metric['correlation_true_pred'][1] = list(overall_metric['correlation_true_pred'][1])\n",
    "\n",
    "\n",
    "    # LOOCV folds: split{i}_test_score (number of data points minus one) \n",
    "    overall_metric['fold_scores'] = [out_model.cv_results_[f'split{i}_test_score'][out_model.best_index_] for i in range(out_model.n_splits_)]\n",
    "    best_params = out_model.best_params_\n",
    "\n",
    "\n",
    "    # printing section\n",
    "    print(\"best parameter from gridsearch>>\\n\", out_model.best_params_)\n",
    "    print(overall_metric['CV'])\n",
    "    print(overall_metric['scoring_metric'])\n",
    "    print(\"correlation Matrix>>\\n\", overall_metric['correlation_true_pred'])\n",
    "    print(\"scores for each fold>>\\n\",overall_metric['fold_scores'])\n",
    "\n",
    "    if str(model).startswith(\"Lasso\"):\n",
    "        # access the 'regressor' step from the best pipeline and then its coefficients\n",
    "        coefficients = best_pipeline.named_steps['regressor'].coef_\n",
    "        overall_metric['non_zero_coefficients'] = coefficients[coefficients != 0]\n",
    "        overall_metric['non_zero_coefficients'] = overall_metric['non_zero_coefficients'].tolist()\n",
    "        overall_metric['non_zero_features'] = list(X.columns[np.where(coefficients != 0)[0]])\n",
    "        print(\"non_zero_features>>\\n\",overall_metric['non_zero_features'])\n",
    "\n",
    "    if str(model).startswith(\"RandomForestRegressor\"):\n",
    "        pass\n",
    "        print(\"<<gridcv done>>\")\n",
    "        #feature_names = X.columns\n",
    "        #feature_importances = best_pipeline.named_steps['regressor'].feature_importances_\n",
    "        #feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "        #sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        #overall_metric['feature_importances'] = OrderedDict(sorted_feature_importance)\n",
    "        #print(\"feature_importances>>\\n\",overall_metric['feature_importances'])\n",
    "       \n",
    "\n",
    "    return overall_metric, out_model, best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_type(obj):\n",
    "    \"\"\"\n",
    "    Converts an type of numpy into a python inherent type\n",
    "    This function can be used in combination with json.dump:\n",
    "    ----\n",
    "    Usage Example:\n",
    "    \n",
    "    with open(f\"{output_path}{output_prefix}_nXcv.json\", 'w') as file:\n",
    "       json.dump(cv_results, file, default=convert_type)\n",
    "    \"\"\"\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "def nX_cross_validation(X, target, param_grid, scorer_estimate, output_prefix, random_states, output_path='./models/10xKfold/', n_splits=3, cv_n_jobs=1, regr_n_job=1):\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"The path {output_path} exists.\")\n",
    "    else:\n",
    "        print(f\"The path {output_path} does not exist.\")\n",
    "        raise FileNotFoundError(f\"The path {output_path} does not exist.\")\n",
    "    best_fold_mean = float('-inf')\n",
    "    best_model = []\n",
    "\n",
    "    #cv_results = {'random_state': [], 'scores': {}, 'mean_scores': [], 'selected_features': {}, 'common_features': {}, 'model': {}}\n",
    "    cv_results = {'random_state': [], 'scores': {}, 'mean_scores': [], 'selected_features': {}, 'best_param': []}\n",
    "\n",
    "    for ran_state in random_states:\n",
    "        print(ran_state)\n",
    "        kfold_cv = KFold(n_splits=n_splits, shuffle=True, random_state=ran_state)\n",
    "        scores, model, best_param = gridcv(\n",
    "            X, \n",
    "            target,\n",
    "            RandomForestRegressor(n_jobs=regr_n_job),\n",
    "            param_grid,\n",
    "            prepy=False,\n",
    "            scorer=scorer_estimate, \n",
    "            cv_meth=kfold_cv,\n",
    "            cv_n_jobs=cv_n_jobs\n",
    "        )\n",
    "        cv_results['random_state'].append(ran_state)\n",
    "        cv_results['scores'][ran_state] = scores\n",
    "        cv_results['mean_scores'].append(np.mean(scores['fold_scores']))\n",
    "        if best_fold_mean < np.mean(scores['fold_scores']):\n",
    "            best_fold_mean = np.mean(scores['fold_scores'])\n",
    "            cv_results['best_param'] = best_param, ran_state, np.mean(scores['fold_scores'])\n",
    "\n",
    "    # REF 1\n",
    "\n",
    "    print(f\"best estimator>>\\n found in split: {cv_results['best_param'][1]}\\n param_grid: {cv_results['best_param'][0]}\\n mean fold score {cv_results['best_param'][2]}\")    \n",
    "    regr = RandomForestRegressor(max_features=cv_results['best_param'][0]['regressor__max_features'], n_estimators=cv_results['best_param'][0]['regressor__n_estimators'], bootstrap=cv_results['best_param'][0]['regressor__bootstrap'], n_jobs=regr_n_job)\n",
    "    best_model = regr.fit(X, target)\n",
    "    feature_names = X.columns\n",
    "    feature_importances = best_model.feature_importances_\n",
    "    feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "    sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_feature_importance = OrderedDict(sorted_feature_importance)\n",
    "    # select feature based on cumulative importance\n",
    "    cumulative_importance = 0.0\n",
    "    selected_features = []\n",
    "    for feature, importance in sorted_feature_importance.items():\n",
    "        #print(f\"feaute, {feature},  import, {importance}\")\n",
    "        cumulative_importance += importance\n",
    "        selected_features.append(feature)\n",
    "        if cumulative_importance >= 0.95:\n",
    "            break\n",
    "    cv_results['selected_features'] = selected_features\n",
    "\n",
    "    #save to json\n",
    "    with open(f\"{output_path}{output_prefix}_nXcv.json\", 'w') as file:\n",
    "       json.dump(cv_results, file, default=convert_type)\n",
    "    file.close()\n",
    "    \n",
    "    return cv_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_valid_variable_name(name):\n",
    "    # Replace special characters with underscores\n",
    "    name = re.sub(r'\\W|^(?=\\d)', '_', name)\n",
    "    # Reduce multiple consecutive underscores to one\n",
    "    name = re.sub(r'_{2,}', '_', name)\n",
    "    # Truncate length if necessary\n",
    "    max_length = 30\n",
    "    if len(name) > max_length:\n",
    "        name = name[:max_length]\n",
    "    # Ensure it doesn't start with a number\n",
    "    if name[0].isdigit():\n",
    "        name = \"_\" + name\n",
    "    return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gcms_mut = pd.read_csv(\"/home/t44p/PW_rawdata/tr_gc_mutual/gcms_mut.csv\", sep=\",\")\n",
    "#lcms_mut = pd.read_csv(\"/home/t44p/PW_rawdata/tr_gc_mutual/lcms_mut.csv\", sep=\",\")\n",
    "gcms_mut = pd.read_csv(\"/work/yhesse/PW_rawdata/tr_gc_mutual/gcms_mut.csv\", sep=\",\")\n",
    "lcms_mut = pd.read_csv(\"/work/yhesse/PW_rawdata/tr_gc_mutual/lcms_mut.csv\", sep=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"/work/yhesse/PW_rawdata/tr_gc_mutual/tr_wgcna_MEs.csv\", sep=\",\", index_col=0)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcms_target_dict = {}\n",
    "for target in gcms_mut['metabolite']:\n",
    "    o = to_valid_variable_name(target)\n",
    "    #print(f\"{o} == \\t {target}\")\n",
    "    gcms_target_dict[o] = str(target)\n",
    "\n",
    "\n",
    "lcms_target_dict = {}\n",
    "for target in lcms_mut['metabolite']:\n",
    "    o = to_valid_variable_name(target)\n",
    "    #print(f\"{o} == \\t {target}\")\n",
    "    lcms_target_dict[o] = str(target)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tenX = [42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]\n",
    "tenX = [42, 43 ]\n",
    "cvcpu = 2\n",
    "rgrcpu = 2\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': np.array(np.arange(500, 1501, 200)),\n",
    "    'regressor__max_features': np.round(np.exp2(np.array(np.arange(3.2, 13.3, 2)))).astype(int),\n",
    "    'regressor__bootstrap': [False]\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = '/work/yhesse/jobs/xele_ml/full_rfr/gcms/'\n",
    "\n",
    "print(f\"param_grid >>> {param_grid}\")\n",
    "for i, (gcms_target, orig_str) in enumerate(gcms_target_dict.items()):\n",
    "    now = datetime.now()\n",
    "    print(f\"\\n>> START {gcms_target} {now.isoformat()} <<\")\n",
    "    tmp_10xKfold = nX_cross_validation(X.iloc[:,:], gcms_mut.iloc[i,1:], param_grid, 'r2', str(gcms_target), random_states=tenX, output_path=out, cv_n_jobs=cvcpu, regr_n_job=rgrcpu)\n",
    "    print(f\"\\n>> DONE <<\\n\\n\")\n",
    " \n",
    "\n",
    "with open(f\"{out}gcms_dict_nXcv.json\", 'w') as file:\n",
    "    json.dump(gcms_target_dict, file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = '/work/yhesse/jobs/xele_ml/full_rfr/lcms/'\n",
    "\n",
    "for i, (lcms_target, orig_str) in enumerate(lcms_target_dict.items()):\n",
    "    now = datetime.now()\n",
    "    print(f\"\\n>> START {lcms_target} {now.isoformat()} <<\")\n",
    "    tmp_10xKfold = nX_cross_validation(X.iloc[:,:], lcms_mut.iloc[i,1:], param_grid, 'r2', str(lcms_target), random_states=tenX, output_path=out, cv_n_jobs=5, regr_n_job=5)\n",
    "    print(f\"\\n>> DONE <<\\n\\n\")\n",
    " \n",
    "\n",
    "with open(f\"{out}lcms_dict_nXcv.json\", 'w') as file:\n",
    "    json.dump(lcms_target_dict, file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
